# Chapter 2: File input/output

Okay, so Chapter 1 was the whole enchilada...

... *d-mnit, now I'm HANGRY!*

... everything else is just details.

So: details.

## Lines

We want to read a CSV (comma separated values) file and count the number of
lines in the file. Because who doesn't want to do that? That is: process a
file, line-by-line.

We doesn't not want to do that, that's who! SO THERE!

The CSV file is [here](/src/book/book1/cmc-coins.csv)

This program reads the file name from the command line (as opposed to reading
from standard input), then 'parses' the file by breaking it up by lines and
counting the lines, returning that as the result.

So. What do I call this thing? That's always the hardest thing for me: names,
naming characters in my stories, naming programs, naming functions.

Names.

I'll name this program `wc`.

```Haskell
import System.Environment (getArgs)

main :: IO ()
main = getArgs >>=  mapM_ wc

wc :: FilePath -> IO ()
wc f = readFile f >>= 
       putStrLn 
              . ((f ++ " has ") ++) . (++ " lines.")
              . show . length . lines
```

[src](/src/book/book1/ex2a-line-count.hs)

### Unus

```bash
$ cd src/book/book1
$ ghc ex2a-line-count.hs -o wc
```

... *program compiles, like, instantaneously*

```bash
$ ./wc cmc-coins.csv
cmc-coins.csv has 33 lines.
```

### Explanation

Is there a lot to unpack here? Not really.

1. We import `getArgs` to get all the files to process
2. We then loop through each file, mapping the file name to a process, `wc`.

In `wc`, we:

3. read the file, obvie.
4. Then, going backwards from here *(because `(.)` pipes the flow of data 
from right to left)*

<blockquote>
<ol type='a'>
   <li><code>lines</code> breaks the file into an array of lines</li>
   <li><code>length</code> converts a list into its length (or: *folds* the list into the 
count)</li>
   <li><code>show</code> converts any (showable) value to its string representation</li>
   <li>which then feeds that result (the line-count) to the output string.</li>
</ol>
</blockquote>

### Duus

Okay, that was one file, can we do more than one file? Let's try.

```bash
./wc cmc-coins.csv ex2-wc.hs
cmc-coins.csv has 33 lines.
ex2a-line-count.hs has 13 lines.
```

That was easy!

Note something interesting here: the program `ex2a-line-count.hs` counts the
lines of files (data), but it, itself, is data for the program.

The program is data!

Computer scientists get all excited about stuff like this.

## Words

Okay, we've counted the lines of files, but let's look, in particular, at 
the CSV file. The first few lines look like this:

```CSV
Coin Prices,,,,
,,,,
for_date,cmc_id,coin,price (USD),id
2022-07-09,7278,AAVE,$74.50,
2022-07-09,4030,ALGO,$0.32,
```

Here we see the first three lines are meta-data.

You know what meta-data is?

Useless to us in this exercise.*

*translation "this exercise": always.

So, we want to drop the first three lines.

Now, the other lines, we want to get the token name (coin) and the cmc_id, so
we can, eventually, print it out, but let's store it in a structure as we read
the file:

```Haskell
data Coin = Coin { cmc_id :: Integer, name :: String }
   deriving (Eq, Ord, Show)
```

A data-structure is all well and good, but we need to scan each line and extract
the associated values. And how do we do that? We [split](https://stackoverflow.com/questions/4978578/how-to-split-a-string-in-haskell) the line into its
distinct elements, then populate the Coin data type with the relevant values.

Our new program looks like this:

```Haskell
import System.Environment (getArgs)

data Coin = Coin { cmc_id :: Integer, name :: String }
   deriving (Eq, Ord, Show)

main :: IO ()
main = getArgs >>= mapM_ coinM

coinM :: FilePath -> IO ()
coinM f = putStrLn ("Coins in " ++ f ++ ":\n") >>
          readFile f >>=
          mapM_ print . map (encoin . csv) . drop 3 . lines

csv :: String -> [String]
csv = split ','

-- https://stackoverflow.com/questions/4978578/how-to-split-a-string-in-haskell
-- Frank Meisschaert answer

split :: Char -> String -> [String]
split d [] = []
split d s = x : split d (drop 1 y) where (x,y) = span (/= d) s

encoin :: [String] -> Coin
encoin (_:cmc_id:name:_) = Coin (read cmc_id) name
```

[src](/src/book/book1/ex2b-csv-parser.hs)

And we run this puppy thusly:

```bash
$ cd src/book/book1/
$ ghc ex2b-csv-parser.hs -o cs
```

... `cs` *for 'coin scanner.'*

```txt
$ ./cs cmc-coins.csv 
Coins in cmc-coins.csv:

Coin {cmc_id = 7278, name = "AAVE"}
Coin {cmc_id = 4030, name = "ALGO"}
Coin {cmc_id = 8857, name = "ANC"}
Coin {cmc_id = 3794, name = "ATOM"}
... etc
```

GREAT! It worked! Calloo! Callay! Get up and do your happy dance!

### Error handling

#### `Maybe` monad

But what if it doesn't work.

Haskellonians seem to think the world is this well-ordered place where inputs
are well-behaved, so you always get outputs.

But then your code goes to production, and you pull a 72-hour shift hardening
everything. Fun! ... NOT!

What am I talking about?

Let's run `cs` against [this file](/src/book/book1/cmc-coins-bad-line.csv):

```txt
$ ./cs cmc-coins-bad-line.csv 
Coins in cmc-coins-bad-line.csv:

Coin {cmc_id = 7278, name = "AAVE"}
Coin {cmc_id = 4030, name = "ALGO"}
Coin {cmc_id = 8857, name = "ANC"}
Coin {cmc_id = 3794, name = "ATOM"}
Coin {cmc_id = 8602, name = "AUCTION"}
Coin {cmc_id = 5805, name = "AVAX"}
Coin {cmc_id = 1839, name = "BNB"}
Coin {cmc_id = 1, name = "BTC"}
cs: ex2b-csv-parser.hs:25:1-50: Non-exhaustive patterns in function encoin
```

... *program exits*

So: not good! The data did not meet our expectations, or: some of it didn't;
most of it did? So, how do we process data that we can, and don't fail on what
we can't process, ... gracefully?

#### Maybe monad

One approach is the `Maybe` monad that is either a success value or failure.

... Prolog, anyone?

*sigh* I'm a Prolog programmer: you're going to be hearing the Prolog-lament
from me, oftenly.

Yes: 'oftenly' is a word, or it should be.

So, with the `Maybe` monad, we either succeed in parsing the line into a 
`Coin`-value (returning that `Coin`-value), or we don't. Here's what that looks
like in code...

... and, actually, as the changes are slight, I'll just show the diffs:

```diff
0a1
> import Data.Maybe (mapMaybe)
12c13
>           mapM_ print . mapMaybe (encoin . csv) . drop 3 . lines
24,25c25,27
> encoin :: [String] -> Maybe Coin
> encoin (_:cmc_id:name:_) = Just $ Coin (read cmc_id) name
> encoin _ = Nothing
```

and the full source code is [here](/src/book/book1/ex2c-maybe-csv-parser.hs).

Running this program concludes successfully:

```TXT
$ ./mcs cmc-coins-bad-line.csv 
Coins in cmc-coins-bad-line.csv:

Coin {cmc_id = 7278, name = "AAVE"}
Coin {cmc_id = 4030, name = "ALGO"}
Coin {cmc_id = 8857, name = "ANC"}
Coin {cmc_id = 3794, name = "ATOM"}
Coin {cmc_id = 8602, name = "AUCTION"}
...
Coin {cmc_id = 7083, name = "UNI"}
Coin {cmc_id = 52, name = "XRP"}
Coin {cmc_id = 2011, name = "XTZ"}
Coin {cmc_id = 10820, name = "YLDY"}
Coin {cmc_id = 1896, name = "ZRX"}
$
```

*Ã€ propos de rein,* I *do* so miss FORTH's `READY>`-prompt.

#### `Either` monad

Okay, that ... *"succeeds"???*

Well, the program runs to completion, and it gives you a result. However, what
if there were non-obvious bad data in the source file? I mean a bad line with
'gnurrs coming out of the voodverk out' is obvious, but what if we had a line 
that was *MOSTLY* correct (like *"MOSTLY* dead," eh?). We'd parse the file to 
completion, but we'd be missing data. Necessary data? Essential data? Given
the above program, we'll never know.

This not knowing displeased Hilbert mightily.

Let's know.

How know?

`Either`.

The `Either` data type allows you to encode information on, well: *either* 
branch of control-flow. So, if the function succeeds, you can encode that
success on the `Left`-side, but, importantly, if it fails, you can encode what
failed on the `Right`-side. This will allow us to inform, well: us, of what 
failures occurred during our parsing exercise.

Now, the changes from `Maybe`-monad to `Either`-monad are more significant, so
I present the new implementation in full:

```Haskell
import Data.Either (partitionEithers)
import Data.Maybe (listToMaybe)
import System.Environment (getArgs)

data Coin = Coin { cmc_id :: Integer, name :: String }
   deriving (Eq, Ord, Show)

main :: IO ()
main = getArgs >>= mapM_ coinM

coinM :: FilePath -> IO ()
coinM f = putStrLn ("Coins in " ++ f ++ ":\n") >>
          readFile f >>= 
          uncurry (resultsAndErrors f) . partitionEithers
                . map (encoin . csv) . drop 3 . lines

resultsAndErrors :: FilePath -> [Coin] -> [String] -> IO ()
resultsAndErrors f coins errs = results f coins >> nl >> errors f errs

nl :: IO ()
nl = putStrLn ""

results :: FilePath -> [Coin] -> IO ()
results f coins = mapM_ print coins

errors :: FilePath -> [String] -> IO ()
errors _ [] = return ()
errors f lines =
   mapM_ putStrLn (("Didn't parse following lines in " ++ f ++ ":"):"":lines)

csv :: String -> [String]
csv = split ','

-- https://stackoverflow.com/questions/4978578/how-to-split-a-string-in-haskell
-- Frank Meisschaert answer

split :: Char -> String -> [String]
split d [] = []
split d s = x : split d (drop 1 y) where (x,y) = span (/= d) s

encoin :: [String] -> Either Coin String
encoin (_:cmc_id:name:_) =
   maybe (Right ("Could not parse " ++ cmc_id ++ " as cmc_id."))
         (Left . flip Coin name . fst) (listToMaybe $ reads cmc_id)
encoin line = Right $ show line
```

[src](/src/book/book1/ex2d-either-csv-parser.hs)

Okay, let's run it against good data. What do we get?

```TXT
$ ./ecs cmc-coins.csv                 
Coins in cmc-coins.csv:

Coin {cmc_id = 7278, name = "AAVE"}
Coin {cmc_id = 4030, name = "ALGO"}
Coin {cmc_id = 8857, name = "ANC"}
...
Coin {cmc_id = 2011, name = "XTZ"}
Coin {cmc_id = 10820, name = "YLDY"}
Coin {cmc_id = 1896, name = "ZRX"}
```

That looks good.

Now, let's try the bad data:

```TXT
$ ./ecs cmc-coins-bad-line.csv
Coins in cmc-coins-bad-line.csv:

Coin {cmc_id = 7278, name = "AAVE"}
Coin {cmc_id = 4030, name = "ALGO"}
Coin {cmc_id = 8857, name = "ANC"}
...

Coin {cmc_id = 2011, name = "XTZ"}
Coin {cmc_id = 10820, name = "YLDY"}
Coin {cmc_id = 1896, name = "ZRX"}

Didn't parse following lines in cmc-coins-bad-line.csv:

["The gnurrs come from the voodverk out.\r"]
Could not parse sigh as cmc_id.
```

Sweet!

#### Analysis

Okay, so: what are we doing here? In the `Maybe`-implementation, we parsed each
line, and those lines we couldn't parse, we dropped on the floor.

Here, we have `resultsAndError` that partitions the parsed results, reporting
them out, but then it also shows each line that it could not parse.

But 'each line it could not parse' is more than a binary parse-or-not-parse
proposition. What happens if you try to parse an non-numeric cmc_id? That's
an error, too, and we need to handle that gracefully. That's why the
`encoin`-function's implementation is that much more complicated: it guards 
parsing the cmc_id.

#### Pop quiz 2

It's nice that we're getting error-reporting, but that error-reporting is
rudimentary, at best. Rewrite the program that shows the line number where
each error occurred.

[answer](/src/book/book1/quizzy2-line-number-errs.hs) *(but don't look at the 
answer until you've solved it for yourself)*

#### Pop quiz 3

Look up how to write to `stderr`. If you don't know what `stderr` is, look up
what `stderr` is. Now: redirect the messages about errors in parsing to
`stderr`.

[answer](/src/book/book1/quizzy3-stderr.hs) *(same, no peekin')*

#### Analysis

Once we have `stderr`-output implemented we can do things like direct the 
parsed result to one file and the error report to another, thusly:

```BASH
$ ./quizzy3 "cmc-coins-bad-line.csv" > coins.hs 2> errs.txt
```

### File Output

So, we ended the previous section redirecting the standard output to files: all
very unix-y. We can also direct output to files inside our program. We read
files with `readFile`; we can write files with, well: `writeFile`. 

Correspondingly, we broke apart a file into rows with `lines`; we can stitch
together a set of rows into a file (or an unified string, more precisely) with
`unlines`.

So, let's save out our parsed data to `coins.out`.

I'll provide a link to the full source, but let's examine the relevant changes:

```HASKELL
results :: FilePath -> [Coin] -> IO ()
results f = writeFile f . unlines . map show
```

You see that `results` has the exact same function-signature, but instead of

```HASKELL
mapM_ print
```

we have

```HASKELL
writeFile f . unlines . map show
```

where `map show` converts the `Coin`-type to `String`-values, `unlines` stitches
the rows into one string that `writeFile f` saves to file, `f`.

## Conclusion

What have we learned today?

(I just seriously wrote that.)

1. We learned how to read files, processing them by line.
2. We learned how to read files, processing each line by comma-separated value.
3. We learned how write files.

### Caveat

More importantly, yet unwritten here, is we learned that Haskell can be its own
ecosystem, but it can be *part* of a larger ecosystem. Reading and writing files
is all very well and good (which one is it, m8?), but files denote permanence.
If you're reading a file, it may live on much longer than its usefulness. If
you're writing a file, it will live on, consuming space, until you delete it, 
... or forever, ... whichever comes first (usually the latter, eh?).

* Why read a file when you can pipe ('`|`') it in?
* Why write a file when you can pipe ('`|`') it or cat ('`>`') it out?

I think programmers, in general, are too quick to rely on files as the medium
of exchange, and this reliance is wrong when the exchange occurs only once.
